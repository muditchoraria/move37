{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In cartpole environment, there are *4* observations at any state (including the angle of position and position of the cart). Using these observations, the agent decides one of the two actions: move the cart left or right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91767288, -0.35398954,  0.76289935,  0.31637574])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random initialisation between [-1,1]\n",
    "import numpy as np\n",
    "parameters = np.random.rand(4) * 2 - 1\n",
    "parameters\n",
    "#Use inner product to find the inner product to see which\n",
    "#action leads to better results/rewards\n",
    "#action = 0 if np.matmul(parameters, observation) < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"observation is the environment-specific object that represents our observation of environment\\nreward is the amount of reward by previous action\\ndone is the boolean that says whether it's time to reset the environment. True indicates the termination of episode\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Search method\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_episode(env, parameters):\n",
    "    observation = env.reset()\n",
    "    totalreward = 0\n",
    "    for _ in range(200):\n",
    "        action = 0 if np.matmul(parameters, observation) < 0 else 1\n",
    "        #env.render()\n",
    "        observation, reward, done, info = env.step(action) #take that action\n",
    "        totalreward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return totalreward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation** is the environment-specific object that represents our observation of environment\n",
    "**reward** is the amount of reward by previous action\n",
    "**done** is the boolean that says whether it's time to reset the environment. True indicates the termination of episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(submit):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    if submit:\n",
    "        env.monitor.start('cartpole-experiments/', force = True)\n",
    "    counter = 0\n",
    "    bestparams = None\n",
    "    bestreward = 0\n",
    "    for _ in range(10000):\n",
    "        parameters = np.random.rand(4) * 2 - 1 \n",
    "        counter += 1\n",
    "        reward = run_episode(env, parameters)\n",
    "        if reward > bestreward:\n",
    "            bestreward = reward\n",
    "            bestparams = parameters\n",
    "            # considered solved if the agent lasts 200 timesteps\n",
    "            if reward == 200:\n",
    "                break\n",
    "    \n",
    "    if submit:\n",
    "        for _ in range(100):\n",
    "            run_episode(env, bestparams)\n",
    "        env.monitor.close()\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.322\n"
     ]
    }
   ],
   "source": [
    "# train an agent to submit to openai gym\n",
    "# train(submit=True)\n",
    "\n",
    "# create graphs\n",
    "results = []\n",
    "for _ in range(100):\n",
    "    results.append(train(submit=False))\n",
    "\n",
    "plt.hist(results,50,normed=1, facecolor='r', alpha=0.75)\n",
    "plt.xlabel('Episodes required to reach 200')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Random Search')\n",
    "plt.show()\n",
    "\n",
    "print (np.sum(results) / 1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hill-Climbing approach\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
