{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hill-Climbing Approach\n",
    "\n",
    "Hill-Climbing approach is how we would have intuitively reached some conclusion. Start somewhere (randomly chosen weights) => Gradually take steps to reach the best position (add some noise and update on seeing improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to gradually improve rather than jumping around and being hopeful of getting the best solution. It might still not be the best idea as we may see but may prove better a lot of times.\n",
    "\n",
    "Noise scaling is basically how much random we want to keep our next value wrt current value. A high scaling is basically what random search is.\n",
    "\n",
    "Thus, initial weight initalization holds a major role in how well the agent performs as the improvement is iterative. So if you are stuck at a position that is too far from the best reward, you wont find a good answer. That's why you may find a lot of initializations get stuck and no result is found.\n",
    "\n",
    "A fix to this is increase noise_factor every iteration we see no improvement (Basically implies that increase randomness if you don't see the required change as you are probably not at the right place.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(submit):\n",
    "    env = gym.make('CartPole-v0')\n",
    "    if submit:\n",
    "        env.monitor.start('cartpole-experiments/', force = True)\n",
    "    \n",
    "    episodes_per_update = 5\n",
    "    noise_scaling = 0.1\n",
    "    counter = 0\n",
    "    bestparams = np.random.rand(4) * 2 - 1\n",
    "    bestreward = 0\n",
    "    for _ in range(10000):\n",
    "        parameters = (np.random.rand(4) * 2 - 1)*noise_scaling + bestparams \n",
    "        counter += 1\n",
    "        # This can further improve the solution, instead of updating \n",
    "        # after each iteration, we sum the reward after a number of\n",
    "        # them and update accordingly\n",
    "        # for _ in xrange(episodes_per_update):\n",
    "        #     run = run_episode(env,newparams)\n",
    "        #     reward += run\n",
    "        reward = run_episode(env, parameters)\n",
    "        if reward > bestreward:\n",
    "            bestreward = reward\n",
    "            bestparams = parameters\n",
    "            # considered solved if the agent lasts 200 timesteps\n",
    "            if reward == 200:\n",
    "                break\n",
    "    \n",
    "    if submit:\n",
    "        for _ in range(100):\n",
    "            run_episode(env, bestparams)\n",
    "        env.monitor.close()\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode(env, parameters):\n",
    "    observation = env.reset()\n",
    "    totalreward = 0\n",
    "    counter = 0\n",
    "    for _ in range(200):\n",
    "        action = 0 if np.matmul(parameters, observation) < 0 else 1\n",
    "        #env.render()\n",
    "        observation, reward, done, info = env.step(action) #take that action\n",
    "        totalreward += reward\n",
    "        counter += 1\n",
    "        if done:\n",
    "            break\n",
    "    return totalreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059\n"
     ]
    }
   ],
   "source": [
    "r = train(submit = False)\n",
    "print(r/1000.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
